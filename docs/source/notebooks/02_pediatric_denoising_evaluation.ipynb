{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Denoising Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction \n",
    "\n",
    "Simulated using MIRT as described in [Nelson et al., 2023](https://onlinelibrary.wiley.com/doi/abs/10.1002/mp.16901) where the acquisition parameters are meant to simulate the Siemens Somatom Definition AS+, which is one of the scanners used in developing the [Low Dose CT Grand Challenge Dataset](https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.12345). However I still need to be careful that this is an approximation and there still may be mismatch between the real and simulated scans, though [Zeng et al., 2022](http://onlinelibrary.wiley.com/doi/abs/10.1002/mp.15430) validated the simulations with physical scans based on MTF and NPS performance measures.\n",
    "\n",
    "**Question**: Data augmentation is a common approach for dealing with limited datasets. Can data augmentation techniques be used to make up for limited pediatric data?\n",
    "\n",
    "**Hypothesis**: Noise textures from pediatric-sized phantom scans can be used as an effective data augmentation to improve denoising model generalizability to pediatric patients.\n",
    "\n",
    "*Purpose* to test our hypothesis that training with noise augmentation can improve performance in pediatric patients. This notebook presents the results in terms of denoising efficiency, which we define in two ways depending on the data available.\n",
    "\n",
    "\n",
    "If even that doesn't exist you can select a region that is assumed to be uniform and compare measured standard deviation $\\sigma$ in the region:\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i' - \\mu)^2},\\text{ where } \\mu = \\frac{1}{N} \\sum_{i=1}^N x'_i\n",
    "$$\n",
    "\n",
    "here we assume a uniform region such that that $\\bar{x}$ is assumed to be the true value for an unbiased measurement in a uniform region\n",
    "\n",
    "We can thus define noise reduction both in terms of noise std [HU] and RMSE as:\n",
    "\n",
    "$$\n",
    "\\text{Noise Reduction} = 100\\% \\times \\frac{(\\text{FBP} - \\text{denoised})}{\\text{FBP}}\n",
    "$$\n",
    "\n",
    "Defining noise reduction relative to the original FBP noise level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Reduction in Uniform Phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydicom\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_and_extract_archive\n\u001b[1;32m     10\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_dir\u001b[38;5;241m.\u001b[39mexists():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "base_dir = Path('data')\n",
    "\n",
    "if not base_dir.exists():\n",
    "    url ='https://zenodo.org/records/11267694/files/pediatricIQphantoms.zip'\n",
    "    download_and_extract_archive(url, download_root=base_dir)\n",
    "base_dir = base_dir / 'pediatricIQphantoms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls data/pediatricIQphantoms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(base_dir / 'metadata.csv')\n",
    "meta = meta[meta.phantom == 'uniform']\n",
    "meta.file = meta.file.apply(lambda o: base_dir.absolute() / o)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(meta['FOV [cm]'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import browse_studies, study_viewer\n",
    "browse_studies(meta, phantom='uniform', fov=12, dose=100, recon='fbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_viewer(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from denoising.networks import RED_CNN\n",
    "\n",
    "def read_dicom(dcm_file):\n",
    "    dcm = pydicom.read_file(dcm_file)\n",
    "    return dcm.pixel_array + float(dcm.RescaleIntercept)\n",
    "\n",
    "def load_model(save_path, iter_=13000, multi_gpu=False):\n",
    "    REDCNN = RED_CNN()\n",
    "    f = os.path.join(save_path, 'REDCNN_{}iter.ckpt'.format(iter_))\n",
    "    REDCNN.load_state_dict(torch.load(f))\n",
    "    return REDCNN\n",
    "\n",
    "denoising_model  = load_model('denoising/models/redcnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta.studyid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.array([read_dicom(o) for o in meta[meta['studyid'] == 64].file])\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "denoising_model.to(device)\n",
    "batch_size = 32 #play around with an inference batch size that fits on your gpu\n",
    "\n",
    "denoised = denoising_model.predict(vol[:, None], device=device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta[(meta['Dose [%]'] == 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metae you could just apply the denoiser to each row individually, that would not be an efficient use of the gpu which work well with mini batches (if using a gpu, if using cpu it shouldn't matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "count = 0\n",
    "studyids = meta[(meta['Dose [%]'] == 25)].studyid.unique()\n",
    "for study in studyids:\n",
    "    print(f'denoising batch: {count}/{len(studyids)}')\n",
    "    vol = np.array([read_dicom(o) for o in meta[meta['studyid'] == study].file])\n",
    "    denoised = denoising_model.predict(vol[:, None], device=device, batch_size=batch_size) # replace with your own model here <--\n",
    "    # save result\n",
    "    slice_idx = 0\n",
    "    for idx, row in meta[meta['studyid'] == study].iterrows():\n",
    "        rows.append(pd.DataFrame(row).T)\n",
    "        new_row = row.copy()\n",
    "\n",
    "        dcm = pydicom.read_file(row.file)\n",
    "        new_row.recon = 'RED-CNN'\n",
    "        dcm.ConvolutionKernel = new_row.recon\n",
    "        dcm.PixelData = denoised[slice_idx].astype('int16') - int(dcm.RescaleIntercept)\n",
    "        slice_idx += 1\n",
    "        save_file = Path(str(row.file).replace('fbp', new_row.recon))\n",
    "        save_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "        pydicom.write_file(save_file, dcm)\n",
    "\n",
    "        new_row.file = save_file\n",
    "        rows.append(pd.DataFrame(new_row).T)\n",
    "    count += 1\n",
    "results = pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "browse_studies(results, phantom='uniform', fov=12, dose=25, recon='RED-CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_viewer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import make_montage\n",
    "plt.figure(dpi=300)\n",
    "make_montage(results, roi_diameter=0.4, fovs=[12, 24], wwwl=(150, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import measure_roi_std\n",
    "%timeit measure_roi_std(results.file.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "31/1000*3200/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about 1-2 min to make all of the noise measurements across 3200 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results['noise std [HU]'] = results.file.apply(measure_roi_std)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data=results, x='FOV [cm]', y='noise std [HU]', hue='recon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import calculate_noise_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = calculate_noise_reduction(results)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=results, x='FOV [cm]', y='noise std [HU] reduction [%]', hue='recon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Subgroup': ['Newborn', 'Infant', 'Child', 'Adolescent', 'Adult'],\n",
    "                   'Diameter [cm]':[11.5, 16.8, 23.2, 34, 38],\n",
    "                   'Age [yrs]': [0, 2, 12, 21, 38]})\n",
    "f, ax=plt.subplots(figsize=(3.5,3), dpi=150)\n",
    "df.plot.bar(ax=ax, x='Subgroup',y='Diameter [cm]', table=True, legend=False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.set_ylabel('Mean Effective Diameter [cm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "sns.barplot(data=results[results.recon != 'fbp'], x='pediatric subgroup', y='noise std [HU] reduction [%]', hue='recon', capsize=0.15, ax=ax)\n",
    "f.savefig('../pediatric_subgroup_performance.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
