{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd38e169-5d21-4436-af41-9fd2d79a7fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab62b6-fbdf-47ad-a0ea-42804c3be2d0",
   "metadata": {},
   "source": [
    "This notebook provides an example of converting a metaheader dataset to DICOM.\n",
    "\n",
    "Why?\n",
    "\n",
    "Metaheader datasets are simple raw \"brick of pixels\" data formats with a simple header file with pixel size and orientation information. This header can be either saved as a separate file `.mhd` file by convention, or prepended to the dataset. While simple and useful for research purposes, meta header files are not commonly used in clinical images, DICOM files are the standard there. DICOM files are more complicated but have much more information that can be encoded, which leads to the complications. This notebook does not teach you much about what all of the DICOM header info means, but it does give hands on examples of what elements are changd and how"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca034fda-a33d-408a-8a71-6cd0dc2b740e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Organize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7e24c6-6062-457e-96d5-024301461995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry_info.csv     I0_0075000\t    I0_0255000_processed\n",
      "I0_0010000\t      I0_0075000_processed  I0_0300000\n",
      "I0_0010000_processed  I0_0085000\t    I0_0300000_processed\n",
      "I0_0025000\t      I0_0085000_processed  image_geometry.png\n",
      "I0_0025000_processed  I0_0100000\t    image_info.csv\n",
      "I0_0030000\t      I0_0100000_processed  noise_free_bkg.raw\n",
      "I0_0030000_processed  I0_0120000\t    noise_free_disk.raw\n",
      "I0_0040000\t      I0_0120000_processed  phantom_info_mm.csv\n",
      "I0_0040000_processed  I0_0165000\t    phantom_info_pix_idx.csv\n",
      "I0_0055000\t      I0_0165000_processed  true_bkg.raw\n",
      "I0_0055000_processed  I0_0210000\t    true_disk.raw\n",
      "I0_0070000\t      I0_0210000_processed\n",
      "I0_0070000_processed  I0_0255000\n"
     ]
    }
   ],
   "source": [
    "!ls /gpfs_projects/brandon.nelson/DLIR_Ped_Generalizability/geometric_phantom_studies/main/geometric/CCT189/monochromatic/diameter112mm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c4a3f-ce4a-4107-a8f3-a8b4dbd0f228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_dir = Path('/gpfs_projects/brandon.nelson/DLIR_Ped_Generalizability/geometric_phantom_studies/main_noise_free/geometric')\n",
    "dst_dir = Path('/gpfs_projects/brandon.nelson/RSTs/pediatricIQphantoms')\n",
    "noise_free_imgs = list(orig_dir.rglob('*/noise_free*.raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca34e20f-45f5-42b7-9a0c-897d0ce98565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "phantom_dict = {'CTP404': 'CTP404', 'MITA-LCD': 'CCT189', 'uniform': 'CCT189'}\n",
    "\n",
    "def get_ground_truth(fname):\n",
    "    fname = Path(fname)\n",
    "    if fname.stem.startswith('signal'):\n",
    "        gt_file = 'noise_free.mhd'\n",
    "        return Path(fname).parents[2] / gt_file\n",
    "    if fname.stem.startswith('ACR464'):\n",
    "        gt_file = 'true.mhd'\n",
    "        return Path(fname).parents[3] / gt_file\n",
    "    else:\n",
    "        gt_file = 'true.mhd'\n",
    "        return Path(fname).parents[2] / gt_file\n",
    "    \n",
    "def write_series_to_dicom(series, save_dir):\n",
    "    # load default dicom files\n",
    "    series = series.copy()\n",
    "    fpath = pydicom.data.get_testdata_file(\"CT_small.dcm\")\n",
    "    ds = pydicom.dcmread(fpath).copy()\n",
    "    # update meta info\n",
    "    ds.Manufacturer = 'Siemens (simulated)'\n",
    "    ds.ManufacturerModelName = 'Definition AS+ (simulated)'\n",
    "\n",
    "    time = datetime.now()\n",
    "    ds.InstanceCreationDate = time.strftime('%Y%m%d')\n",
    "    ds.InstanceCreationTime = time.strftime('%H%M%S')\n",
    "    ds.InstitutionName = 'FDA/CDRH/OSEL/DIDSR'\n",
    "    ds.StudyDate = ds.InstanceCreationDate\n",
    "    ds.StudyTime = ds.InstanceCreationTime\n",
    "    age = series['age [year]']\n",
    "    if not age >= 1:\n",
    "        age = 0\n",
    "    ds.PatientName = series.Name\n",
    "    ds.SeriesNumber = str(1)\n",
    "\n",
    "    ds.PatientAge = f'{int(age):03d}Y'\n",
    "    ds.PatientID = f'{int(series.patientid):03d}'\n",
    "    del(ds.PatientWeight)\n",
    "    del(ds.ContrastBolusRoute)\n",
    "    del(ds.ContrastBolusAgent)\n",
    "    ds.ImageComments = f\"effctive diameter [cm]: {series['effective diameter [cm]']}\"\n",
    "    ds.ScanOptions = 'AXIAL MODE'\n",
    "    ds.ReconstructionDiameter = series['FOV [cm]'] * 10\n",
    "    ds.ConvolutionKernel ='fbp D45'\n",
    "    ds.Exposure = series['Dose [%]']\n",
    "\n",
    "    # load image data\n",
    "    img = sitk.ReadImage(series.file)\n",
    "    ds.StudyDescription = f\"{series['Dose [%]']}% dose \" + series.Name + \" \" + ds.ConvolutionKernel\n",
    "\n",
    "    if series['series'] == 'ground truth':\n",
    "        img = sitk.ReadImage(get_ground_truth(series.file))\n",
    "        vol = sitk.GetArrayFromImage(img)\n",
    "        img = sitk.GetImageFromArray(vol[None])\n",
    "        fov = series['FOV [cm]']*10\n",
    "        img.SetSpacing((fov/512, fov/512, fov/512))\n",
    "        series.Name += '_groundtruth'\n",
    "        ds.StudyDescription = series.Name\n",
    "    \n",
    "    elif series['series'] == 'noise free':\n",
    "        series.Name += '_noisefree'\n",
    "        ds.StudyDescription = series.Name + \" \" + ds.ConvolutionKernel\n",
    "\n",
    "        phantom_str = phantom_dict[phantom]\n",
    "        diameter = int(series['effective diameter [cm]']*10)\n",
    "        diam_filter = np.array([str(diameter) in str(o) for o in noise_free_imgs])\n",
    "        phantom_filter = np.array([str(phantom_str) in str(o) for o in noise_free_imgs])\n",
    "        select_noise_free =  np.array(noise_free_imgs)[diam_filter & phantom_filter]\n",
    "        # print(phantom_str, diameter)\n",
    "        if phantom == 'uniform':\n",
    "            select_noise_free = select_noise_free[[o.stem.endswith('bkg') for o in select_noise_free]]\n",
    "        if phantom == 'MITA-LCD':\n",
    "            select_noise_free = select_noise_free[[o.stem.endswith('disk') for o in select_noise_free]]\n",
    "        \n",
    "        # print(select_noise_free)\n",
    "        assert(len(select_noise_free) == 1)\n",
    "        noise_free_file = select_noise_free[0]\n",
    "        vol = np.fromfile(noise_free_file, dtype='int16').reshape((512, 512))\n",
    "        img = sitk.GetImageFromArray(vol[None]) - 1000\n",
    "    \n",
    "    fov = series['FOV [cm]']*10\n",
    "    img.SetSpacing((fov/512, fov/512, fov/512))\n",
    "    ds.SeriesDescription = ds.StudyDescription\n",
    "\n",
    "    vol = sitk.GetArrayFromImage(img)\n",
    "    if vol.ndim == 2: vol = vol[None]\n",
    "    \n",
    "    ds.Rows, ds.Columns = img.GetHeight(), img.GetWidth()\n",
    "    ds.SliceThickness = img.GetSpacing()[-1]\n",
    "    ds.SpacingBetweenSlices = ds.SliceThickness\n",
    "    ds.DistanceSourceToDetector = 1085.6\n",
    "    ds.DistanceSourceToPatient = 595\n",
    "    ds.PixelSpacing = list(img.GetSpacing()[:2])\n",
    "\n",
    "    ds.KVP = 120\n",
    "    ds.StudyID = str(series['studyid'])\n",
    "    # series instance uid unique for each series\n",
    "    end = ds.SeriesInstanceUID.split('.')[-1]\n",
    "    new_end = str(int(end) + series['studyid'])\n",
    "    ds.SeriesInstanceUID = ds.SeriesInstanceUID.replace(end, new_end)\n",
    "    \n",
    "    # study instance uid unique for each series\n",
    "    end = ds.StudyInstanceUID.split('.')[-1]\n",
    "    new_end = str(int(end) + series['studyid'])\n",
    "    ds.StudyInstanceUID = ds.StudyInstanceUID.replace(end, new_end)\n",
    "    ds.AcquisitionNumber = series['studyid']\n",
    "\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # saveout slices as individual dicom files\n",
    "    fnames = []\n",
    "    for slice_idx, array_slice in enumerate(vol):\n",
    "        ds.InstanceNumber = slice_idx + 1 # image number\n",
    "        # SOP instance UID changes every slice\n",
    "        end = ds.SOPInstanceUID.split('.')[-1]\n",
    "        new_end = str(int(end) + slice_idx + series.name)\n",
    "        ds.SOPInstanceUID = ds.SOPInstanceUID.replace(end, new_end)\n",
    "        # MediaStorageSOPInstanceUID changes every slice\n",
    "        end = ds.file_meta.MediaStorageSOPInstanceUID.split('.')[-1]\n",
    "        new_end = str(int(end) + slice_idx + series.name)\n",
    "        ds.file_meta.MediaStorageSOPInstanceUID = ds.file_meta.MediaStorageSOPInstanceUID.replace(end, new_end)\n",
    "        # slice location and image position changes every slice\n",
    "        ds.SliceLocation = -img.GetDepth()//2*ds.SliceThickness + slice_idx*ds.SliceThickness\n",
    "        ds.ImagePositionPatient[-1] = ds.SliceLocation\n",
    "        ds.ImagePositionPatient[0] = -ds.Rows//2*ds.PixelSpacing[0]\n",
    "        ds.ImagePositionPatient[1] = -ds.Columns//2*ds.PixelSpacing[1]\n",
    "        ds.ImagePositionPatient[2] = ds.SliceLocation\n",
    "        ds.PixelData = array_slice.astype('int16') - int(ds.RescaleIntercept)\n",
    "        if series['series'] == 'simulation':\n",
    "            fname = save_dir / f\"{series.Name.replace('.', '').replace(' cm', 'mm').replace(' ', '_')}_{slice_idx:03d}.dcm\"\n",
    "        else:\n",
    "            fname = save_dir.parents[1] / f\"{series.Name.replace('.', '').replace(' cm', 'mm').replace(' ', '_')}.dcm\"\n",
    "        fnames.append(fname)\n",
    "        pydicom.write_file(fname, ds)\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47885916-e137-43cd-83ed-b2d39e8e5f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [04:31<00:00,  5.66s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m out_meta[\u001b[38;5;241m~\u001b[39mout_meta\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[1;32m     79\u001b[0m out_meta \u001b[38;5;241m=\u001b[39m out_meta[\u001b[38;5;241m~\u001b[39mout_meta\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[0;32m---> 80\u001b[0m out_meta\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m \u001b[43mout_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m out_meta\u001b[38;5;241m.\u001b[39mto_csv(dst_dir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Dev/PediatricCTSizeAugmentation/.data_aug_torch/lib/python3.11/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/PediatricCTSizeAugmentation/.data_aug_torch/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/PediatricCTSizeAugmentation/.data_aug_torch/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Dev/PediatricCTSizeAugmentation/.data_aug_torch/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/PediatricCTSizeAugmentation/.data_aug_torch/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m     78\u001b[0m out_meta[\u001b[38;5;241m~\u001b[39mout_meta\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[1;32m     79\u001b[0m out_meta \u001b[38;5;241m=\u001b[39m out_meta[\u001b[38;5;241m~\u001b[39mout_meta\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[0;32m---> 80\u001b[0m out_meta\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;241m=\u001b[39m out_meta\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m o: Path(o)\u001b[38;5;241m.\u001b[39mrelative_to(\u001b[43msave_dir\u001b[49m))\n\u001b[1;32m     81\u001b[0m out_meta\u001b[38;5;241m.\u001b[39mto_csv(dst_dir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from shutil import rmtree\n",
    "from utils import pediatric_subgroup, subgroup_to_age\n",
    "\n",
    "base_dir = Path('/gpfs_projects/brandon.nelson/PediatricCTSizeDataAugmentation')\n",
    "dst_dir = Path('/gpfs_projects/brandon.nelson/RSTs/pediatricIQphantoms')\n",
    "\n",
    "overwrite=True\n",
    "if overwrite:\n",
    "    \n",
    "    meta = pd.read_csv(base_dir / 'metadata.csv')\n",
    "    meta.loc[meta.phantom == 'CTP404', 'Name']=meta[meta.phantom == 'CTP404']['Name'].apply(lambda o: o.replace('mm', 'cm'))\n",
    "    meta = meta[meta.phantom.isin(['MITA-LCD', 'uniform', 'CTP404']) & meta.recon.isin(['fbp']) & meta['Dose [%]'].isin([25, 100])]\n",
    "    meta['kernel']='D45'\n",
    "    meta['scanner']='Siemens Somatom Definition'\n",
    "    meta.pop('Code #')\n",
    "    meta.pop('ethnicity')\n",
    "    meta.pop('weight percentile')\n",
    "    meta.pop('height [cm]')\n",
    "    meta.pop('weight [kg]')\n",
    "    meta.pop('BMI')\n",
    "    meta.pop('gender')\n",
    "    meta['pediatric subgroup'] = meta['effective diameter [cm]'].apply(pediatric_subgroup)\n",
    "    meta['age [year]'] = meta['pediatric subgroup'].apply(subgroup_to_age)\n",
    "    meta.sort_values(by=['phantom', 'effective diameter [cm]', 'Dose [%]'], inplace=True)\n",
    "    meta = meta[['Name', 'effective diameter [cm]', 'age [year]', 'pediatric subgroup', 'phantom', 'scanner', 'Dose [%]', 'recon', 'kernel', 'FOV [cm]', 'file']]\n",
    "    meta.reset_index(drop=True, inplace=True)\n",
    "    for idx, name in enumerate(meta['Name'].unique()): meta.loc[meta['Name']==name, 'patientid'] = idx\n",
    "    meta['studyid'] = meta.index\n",
    "    \n",
    "    if dst_dir.exists():\n",
    "        rmtree(dst_dir)\n",
    "\n",
    "    df_list = []\n",
    "    # meta = meta.iloc[:2]\n",
    "    studyid = 0\n",
    "    for idx, series in tqdm(meta.iterrows(), total=len(meta)):\n",
    "        phantom = series.phantom\n",
    "        diameter = series['effective diameter [cm]']\n",
    "        dose = series['Dose [%]']\n",
    "        series['series']='simulation'\n",
    "        recon = series.recon\n",
    "        save_subdir = dst_dir / phantom / f'diameter_{int(10*diameter):03d}mm' / f'dose_{dose:03d}' / recon\n",
    "        series['studyid'] = studyid\n",
    "        studyid += 1\n",
    "        fnames = write_series_to_dicom(series, save_subdir)\n",
    "        temp_df = pd.concat(len(fnames)*[pd.DataFrame(series).T], ignore_index=True)\n",
    "        temp_df['repeat']=list(map(lambda o: int(o.stem.split('_')[-1]), fnames)) # get repeat number from filename\n",
    "        temp_df['file']=fnames\n",
    "        df_list.append(temp_df)\n",
    "        # add ground truth\n",
    "        if series['Dose [%]'] == 100:\n",
    "            series['series']='ground truth'\n",
    "            series['studyid'] = studyid\n",
    "            studyid += 1\n",
    "            fnames = write_series_to_dicom(series, save_subdir)\n",
    "            temp_df = pd.concat(len(fnames)*[pd.DataFrame(series).T], ignore_index=True)\n",
    "            temp_df['repeat']=0\n",
    "            temp_df['file']=fnames\n",
    "            df_list.append(temp_df)\n",
    "            # add noise free\n",
    "            series['series']='noise free'\n",
    "            series['studyid'] = studyid\n",
    "            studyid += 1\n",
    "            fnames = write_series_to_dicom(series, save_subdir)\n",
    "            temp_df = pd.concat(len(fnames)*[pd.DataFrame(series).T], ignore_index=True)\n",
    "            temp_df['repeat']=0\n",
    "            temp_df['file']=fnames\n",
    "            df_list.append(temp_df)\n",
    "        \n",
    "    out_meta = pd.concat(df_list, ignore_index=True)\n",
    "    out_meta.loc[out_meta['series'] == 'ground truth', 'recon'] = 'ground truth'\n",
    "    out_meta.loc[out_meta['series'] == 'noise free', 'recon'] = 'noise free'\n",
    "    out_meta.loc[out_meta['series'] == 'ground truth', 'Dose [%]'] = None\n",
    "    out_meta.loc[out_meta['series'] == 'noise free', 'Dose [%]'] = None    \n",
    "    out_meta.loc[out_meta['series'] == 'ground truth', 'kernel'] = None\n",
    "    out_meta.loc[out_meta['series'] == 'noise free', 'kernel'] = None\n",
    "    out_meta[~out_meta.file.duplicated()]\n",
    "    out_meta = out_meta[~out_meta.duplicated()]\n",
    "    out_meta.file = out_meta.file.apply(lambda o: Path(o).relative_to(dst_dir))\n",
    "    out_meta.to_csv(dst_dir/'metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb783ae-1a92-4ef2-84b9-6834946e7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /gpfs_projects/brandon.nelson/RSTs & zip pediatricIQphantoms.zip pediatricIQphantoms/ -r -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2871b-36de-4c44-9df5-368a0bfbecc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
